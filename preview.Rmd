---
title: "AB programación: Dataset de estudiantes"
output: html_notebook
---

## Explicación del dataset

Diego Romero Puyal.

El dataset ha sido sacado de la pagina kaggle: <https://www.kaggle.com/>. De la sección de datasets, específicamente hemos escogido este dataset: <https://www.kaggle.com/datasets/lainguyn123/student-performance-factors>. Este conjunto de datos ofrece una visión completa de diversos factores que afectan al rendimiento de los estudiantes en los exámenes. Incluye información sobre hábitos de estudio, asistencia, participación de los padres y otros aspectos que influyen en el éxito académico.

# Parte 1: carga y exploración de datos.

```{r}
library(readr)
library(skimr)
library(dplyr)
library(esquisse)
library(reshape2)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(moments)
library(caret)


```

primero importamos el dataset, ademas importamos la librería skimr para la mejor visualización de los datos

```{r message=FALSE, warning=TRUE, paged.print=TRUE, show_col_types=}
st <- read_csv("estudiantes.csv", show_col_types = FALSE)
head(st,10, show_col_types = FALSE)
```

Tras un primer vistazo podemos observar que tenemos 20 columnas y tenemos tanto valores numéricos como no numéricos. Ademas sospechamos que hay bastantes valores categóricos. Vamos a analizarlo mas a fondo.

separamos las columnas numéricas de las no numéricas para mejor observación de los datos

```{r}
numeric_columns <- sapply(st, is.numeric)
```

```{r}
lapply(st[!numeric_columns], unique)

```

Aquí podemos ver que todos las columnas no numéricas son categóricas. esto lo tendremos en cuenta para el análisis y la limpieza mas adelante

Ahora buscamos los valores nulos dentro de las columnas

Usamos skim mejor que `summary()` porque da mas información y presentada de forma mas limpia

```{r}
skim(st[!numeric_columns])
```

Se observa que tenemos valores nulos en 3 columnas: `Teacher_Quality`, `Parental_Educational_Level` y `Distance_From_Home` Mas tarde en la limpieza de datos veremos que hacer con ellos.

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
skim(st[numeric_columns])
```

En los datos numéricos al contrario que pasaba en los no numéricos no tenemos ningún valor nulo.

# Parte 2: Limpieza de datos

vemos que tenemos valores nulos en 3 columnas:`Parental_Education_Level`, `Teacher_Quality`, `Distance_from_Home`\
como las 3 columnas son categóricas vamos a usar la moda en las 3 para poner el valor que mas se repite. como en r no existe una función que obtenga la moda directamente la creamos nosotros mismos.

```{r}
getmode <- function(v) {
   uniqv <- unique(v)                     
   uniqv[which.max(tabulate(match(v, uniqv)))]
}
```

```{r}
st <- st %>%
  mutate(
    Teacher_Quality = ifelse(is.na(Teacher_Quality), getmode(Teacher_Quality), Teacher_Quality), #si es NA (TRUE) salta `getmode(columna)`,si es False no cambia nada
    Parental_Education_Level = ifelse(is.na(Parental_Education_Level), getmode(Parental_Education_Level), Parental_Education_Level),
    Distance_from_Home = ifelse(is.na(Distance_from_Home), getmode(Distance_from_Home), Distance_from_Home)
  )

```

el `%\>%` esto es el `pipe`, que esta tomando el df `st`y lo paso como entrada a la siguiente función `mutate()`en este caso. Gracias esto nos evitamos escribir mutate para cada columna, permitiendo "fluir" a la función.

Comprobamos que no hay valores nulos.

```{r}
print(colSums(is.na(st)))
```

No hay valores nulos, lo que nos indica que ha funcionado

## Conversión de valores categóricos en factores de R, gracias a esto conseguimos lo siguiente

-   Los factores permiten a R entender que son datos categóricos y no simples textos\
-   facilita el análisis estadístico y creación de modelos.\
-   Permite establecer ordenes específicos entre categorías si es necesario\
-   Optimiza el uso de memoria de R

Convertimos en factores los categóricos y añadimos orden en algunos de ellos ya que tiene relevancia el orden (low\<medium\<high)

```{r}
st <- st %>%
  mutate(
    Parental_Involvement = factor(Parental_Involvement,
                                levels = c("Low", "Medium", "High"),
                                ordered = TRUE),
    Access_to_Resources = factor(Access_to_Resources,
                               levels = c("Low", "Medium", "High"),
                               ordered = TRUE),
    Extracurricular_Activities = factor(Extracurricular_Activities,
                                      levels = c("No", "Yes")),  
    Motivation_Level = factor(Motivation_Level,
                            levels = c("Low", "Medium", "High"),
                            ordered = TRUE),
    Internet_Access = factor(Internet_Access,
                           levels = c("No", "Yes")),  
    Family_Income = factor(Family_Income,
                         levels = c("Low", "Medium", "High"),
                         ordered = TRUE),
    Teacher_Quality = factor(Teacher_Quality,
                           levels = c("Low", "Medium", "High"),
                           ordered = TRUE),
    School_Type = factor(School_Type),  
    Peer_Influence = factor(Peer_Influence,
                          levels = c("Negative", "Neutral", "Positive"),
                          ordered = TRUE),
    Learning_Disabilities = factor(Learning_Disabilities,
                                 levels = c("No", "Yes")),  
    Parental_Education_Level = factor(Parental_Education_Level,
                                    levels = c("High School", "College", "Postgraduate"),
                                    ordered = TRUE),
    Distance_from_Home = factor(Distance_from_Home,
                              levels = c("Near", "Moderate", "Far"),
                              ordered = TRUE),
    Gender = factor(Gender)  
  )
```

Verificamos que se han convertido en factor.

```{r}
str(st)
```

Devolvemos el csv limpio y trabajaremos con él.

```{r}
write.csv(st, "st_clean.csv", row.names = FALSE)

```

```{r message=FALSE, warning=TRUE, paged.print=TRUE, show_col_types=}
st_clean <- read_csv("st_clean.csv", show_col_types = FALSE)
head(st_clean,10, show_col_types = FALSE)
```

# Parte 3: Análisis de los datos

Primero comprobamos si existe algún tipo de sesgo en los datos que tenemos en genero y recursos.

```{r}
categorical_vars <- c("Gender", "Family_Income", "School_Type", "Learning_Disabilities")

plots <- list()

for (var in categorical_vars) {
  p <- ggplot(st_clean, aes_string(x = var)) +
    geom_bar(fill = "skyblue") +
    theme_minimal() +
    labs(title = paste("Distribución de", var), x = var, y = "Frecuencia") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  plots[[var]] <- p
}

grid.arrange(grobs = plots, nrow = 2, ncol = 2)

```

Sesgo:

-   **Género**: La distribución es equilibrada, lo que sugiere un bajo riesgo de sesgo.
-   **Ingreso Familiar**: Predominan las clases media y baja, lo que puede influir en los análisis.
-   **Tipo de Escuela**: Mayor representación de escuelas públicas, lo cual podría sesgar los resultados si queremos extrapolarlos hacia grupos donde haya una mayoría de escuela privada.
-   **Discapacidades de Aprendizaje**: Baja representación de estudiantes con discapacidades, lo que podría limitar la representatividad de los análisis en este aspecto.

Podríamos concluir que es un análisis que se podría extrapolar hacia el conjunto mayoritario de la población, es decir, gente de clase media sin `learning_disabilities` y que van a la escuela pública sin tener en cuenta el género.

## Mapa de correlaciones.

```{r}
cor_matrix <- cor(st_clean[, sapply(st_clean, is.numeric)], use = "complete.obs")

melted_cor_matrix <- melt(cor_matrix)

ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +
  geom_text(aes(label = round(value, 2)), color = "black", size = 3) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab",
                       name = "Correlación") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 10, hjust = 1)) +
  coord_fixed() +
  labs(title = "Mapa de Correlación de Variables con Números Visible")

```

En este mapa de calor Podemos observar en las variables numéricas cuales son las que tienen mas peso con la nota del examen. que en este caso podemos ver que son `Attendance` y `Hours_Studied`.

## Distribución de las notas

```{r}
ggplot(st_clean, aes(x = Exam_Score)) +
  geom_histogram(binwidth = 2, fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(title = "Histograma de Distribución de Exam_Score",
       x = "nota del Examen",
       y = "Frecuencia")
```

```{r}
mediana_exam_score <- median(st_clean$Exam_Score, na.rm = TRUE)
media_exam_score <- mean(st_clean$Exam_Score, na.rm = TRUE)

cat("Mediana de Exam_Score:", mediana_exam_score, "\n")
cat("Media de Exam_Score:", media_exam_score, "\n")

```

Podemos ver la distribución de notas de los estudiantes que se concentra entre el 60 y el 70. Ademas podemos decir que es un histograma casi simétrico, la media y la mediana están muy cerca una de otra.

El histograma da una interpretación visual, pero para concretar más vamos a buscar un valor cuantitativo para ver si estamos en lo cierto. Para ello hacemos el análisis de skewness.

```{r}

skewness_exam_score <- skewness(st_clean$Exam_Score, na.rm = TRUE)

cat("Coeficiente de asimetría (skewness):", skewness_exam_score, "\n")

if (abs(skewness_exam_score) < 0.5) {
  cat("La distribución es aproximadamente simétrica.\n")
} else if (skewness_exam_score > 0.5) {
  cat("La distribución está sesgada a la derecha.\n")
} else if (skewness_exam_score < -0.5) {
  cat("La distribución está sesgada a la izquierda.\n")
}

```

El coeficiente de asimetría obtenido es **1.644435**, lo que indica que la distribución está sesgada a la derecha. Esto significa que la cola de la distribución es más larga hacia los valores más altos.

## Análisis por género

Vamos a realizar un análisis centrándonos en el género donde veremos si tiene una relevancia en distintas variables como pueden ser: "

```         
Exam_Score,Previous_Scores, Motivation_Level, Tutoring_Sessions, Hours_Studied, Attendance
```

### Notas según género

```{r}
# Crear boxplot para Exam_Score por Gender
boxplot_exam <- ggplot(st_clean, aes(x = Gender, y = Exam_Score, fill = Gender)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Exam_Score por Género",
       x = "Género",
       y = "Notas del Examen") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

# Crear barplot para Exam_Score por Gender
barplot_exam <- st_clean %>%
  group_by(Gender) %>%
  summarise(Media_Exam_Score = mean(Exam_Score, na.rm = TRUE)) %>%
  ggplot(aes(x = Gender, y = Media_Exam_Score, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Media de Exam_Score por Género",
       x = "Género",
       y = "Media de Notas del Examen") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

# Crear boxplot para Previous_Scores por Gender
boxplot_previous <- ggplot(st_clean, aes(x = Gender, y = Previous_Scores, fill = Gender)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Previous_Scores por Género",
       x = "Género",
       y = "Notas Previas") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

# Crear barplot para Previous_Scores por Gender
barplot_previous <- st_clean %>%
  group_by(Gender) %>%
  summarise(Media_Previous_Scores = mean(Previous_Scores, na.rm = TRUE)) %>%
  ggplot(aes(x = Gender, y = Media_Previous_Scores, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Media de Previous_Scores por Género",
       x = "Género",
       y = "Media de Notas Previas") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(
  boxplot_exam, barplot_exam,
  boxplot_previous, barplot_previous,
  nrow = 2, ncol = 2
)

```

```{r}

medias_por_genero <- st_clean %>%
  group_by(Gender) %>%
  summarise(
    Media_Exam_Score = mean(Exam_Score, na.rm = TRUE),
    Media_Previous_Scores = mean(Previous_Scores, na.rm = TRUE)
  )

print(medias_por_genero)
```

Tanto chicas y chicas tienen la misma media.

### Motivación, asistencia, horas de estudio y horas de tutoria según género

```{r}
motivacion_por_genero <- st_clean %>%
  group_by(Gender, Motivation_Level) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ungroup()

grafico_motivacion <- ggplot(motivacion_por_genero, aes(x = Gender, y = Percentage, fill = Motivation_Level)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Distribución porcentual de Motivación por Género",
       x = "Género",
       y = "Porcentaje",
       fill = "Motivación") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

promedio_tutoria_por_genero <- st_clean %>%
  group_by(Gender) %>%
  summarise(Promedio_Tutoring_Sessions = mean(Tutoring_Sessions, na.rm = TRUE))

grafico_tutoria <- ggplot(promedio_tutoria_por_genero, aes(x = Gender, y = Promedio_Tutoring_Sessions, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Promedio de Horas de Tutoría por Género",
       x = "Género",
       y = "Promedio de Horas",
       fill = "Género") +
  geom_text(aes(label = round(Promedio_Tutoring_Sessions, 1)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

promedio_estudio_por_genero <- st_clean %>%
  group_by(Gender) %>%
  summarise(Promedio_Study_Hours = mean(Hours_Studied, na.rm = TRUE))

grafico_estudio <- ggplot(promedio_estudio_por_genero, aes(x = Gender, y = Promedio_Study_Hours, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Promedio de Horas de Estudio por Género",
       x = "Género",
       y = "Promedio de Horas",
       fill = "Género") +
  geom_text(aes(label = round(Promedio_Study_Hours, 1)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

promedio_asistencia_por_genero <- st_clean %>%
  group_by(Gender) %>%
  summarise(Promedio_Attendance = mean(Attendance, na.rm = TRUE))

grafico_asistencia <- ggplot(promedio_asistencia_por_genero, aes(x = Gender, y = Promedio_Attendance, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Promedio de Asistencia por Género",
       x = "Género",
       y = "Promedio de Asistencia",
       fill = "Género") +
  geom_text(aes(label = round(Promedio_Attendance, 1)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(grafico_motivacion, grafico_tutoria, grafico_estudio, grafico_asistencia, nrow = 2, ncol = 2)

```

Se distribuyen de igual manera entre chicos y chicas. El genero no tiene relevancia.

## Análisis según problemas de aprendizaje

```{r}
boxplot_exam <- ggplot(st_clean, aes(x = Learning_Disabilities, y = Exam_Score, fill = Learning_Disabilities)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Exam_Score por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Notas del Examen") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

barplot_exam <- st_clean %>%
  group_by(Learning_Disabilities) %>%
  summarise(Media_Exam_Score = mean(Exam_Score, na.rm = TRUE)) %>%
  ggplot(aes(x = Learning_Disabilities, y = Media_Exam_Score, fill = Learning_Disabilities)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Media de Exam_Score por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Media de Notas del Examen") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

boxplot_previous <- ggplot(st_clean, aes(x = Learning_Disabilities, y = Previous_Scores, fill = Learning_Disabilities)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Previous_Scores por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Notas Previas") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

barplot_previous <- st_clean %>%
  group_by(Learning_Disabilities) %>%
  summarise(Media_Previous_Scores = mean(Previous_Scores, na.rm = TRUE)) %>%
  ggplot(aes(x = Learning_Disabilities, y = Media_Previous_Scores, fill = Learning_Disabilities)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Media de Previous_Scores por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Media de Notas Previas") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(
  boxplot_exam, barplot_exam,
  boxplot_previous, barplot_previous,
  nrow = 2, ncol = 2
)

```

Podemos ver que la existencia de discapacidades para el aprendizaje no tiene influencia en los resultados de los exámenes.

```{r}
motivacion_por_disabilities <- st_clean %>%
  group_by(Learning_Disabilities, Motivation_Level) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ungroup()

grafico_motivacion <- ggplot(motivacion_por_disabilities, aes(x = Learning_Disabilities, y = Percentage, fill = Motivation_Level)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Distribución porcentual de Motivación por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Porcentaje",
       fill = "Motivación") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

promedio_tutoria_por_disabilities <- st_clean %>%
  group_by(Learning_Disabilities) %>%
  summarise(Promedio_Tutoring_Sessions = mean(Tutoring_Sessions, na.rm = TRUE))

grafico_tutoria <- ggplot(promedio_tutoria_por_disabilities, aes(x = Learning_Disabilities, y = Promedio_Tutoring_Sessions, fill = Learning_Disabilities)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Promedio de Horas de Tutoría por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Promedio de Horas",
       fill = "Learning Disabilities") +
  geom_text(aes(label = round(Promedio_Tutoring_Sessions, 1)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

promedio_estudio_por_disabilities <- st_clean %>%
  group_by(Learning_Disabilities) %>%
  summarise(Promedio_Study_Hours = mean(Hours_Studied, na.rm = TRUE))

grafico_estudio <- ggplot(promedio_estudio_por_disabilities, aes(x = Learning_Disabilities, y = Promedio_Study_Hours, fill = Learning_Disabilities)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Promedio de Horas de Estudio por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Promedio de Horas",
       fill = "Learning Disabilities") +
  geom_text(aes(label = round(Promedio_Study_Hours, 1)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

promedio_asistencia_por_disabilities <- st_clean %>%
  group_by(Learning_Disabilities) %>%
  summarise(Promedio_Attendance = mean(Attendance, na.rm = TRUE))

grafico_asistencia <- ggplot(promedio_asistencia_por_disabilities, aes(x = Learning_Disabilities, y = Promedio_Attendance, fill = Learning_Disabilities)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Promedio de Asistencia por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Promedio de Asistencia",
       fill = "Learning Disabilities") +
  geom_text(aes(label = round(Promedio_Attendance, 1)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(grafico_motivacion, grafico_tutoria, grafico_estudio, grafico_asistencia, nrow = 2, ncol = 2)

```

```{r}
grafico_peer_influence <- st_clean %>%
  group_by(Learning_Disabilities, Peer_Influence) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ggplot(aes(x = Learning_Disabilities, y = Percentage, fill = Peer_Influence)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Porcentaje de Peer Influence por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Porcentaje",
       fill = "Peer Influence") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

grafico_parental_involvement <- st_clean %>%
  group_by(Learning_Disabilities, Parental_Involvement) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ggplot(aes(x = Learning_Disabilities, y = Percentage, fill = Parental_Involvement)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Porcentaje de Parental Involvement por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Porcentaje",
       fill = "Parental Involvement") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(grafico_peer_influence, grafico_parental_involvement, nrow = 1, ncol = 2)


```

No hay grandes diferencias entre tener o no tener problemas de aprendizaje

## Análisis según tipo de escuela.

```{r}
boxplot_exam <- ggplot(st_clean, aes(x = School_Type, y = Exam_Score, fill = School_Type)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Exam_Score por School Type",
       x = "School Type",
       y = "Notas del Examen") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

barplot_exam <- st_clean %>%
  group_by(School_Type) %>%
  summarise(Media_Exam_Score = mean(Exam_Score, na.rm = TRUE)) %>%
  ggplot(aes(x = School_Type, y = Media_Exam_Score, fill = School_Type)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Media de Exam_Score por School Type",
       x = "School Type",
       y = "Media de Notas del Examen") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

boxplot_previous <- ggplot(st_clean, aes(x = School_Type, y = Previous_Scores, fill = School_Type)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Previous_Scores por School Type",
       x = "School Type",
       y = "Notas Previas") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

barplot_previous <- st_clean %>%
  group_by(School_Type) %>%
  summarise(Media_Previous_Scores = mean(Previous_Scores, na.rm = TRUE)) %>%
  ggplot(aes(x = School_Type, y = Media_Previous_Scores, fill = School_Type)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Media de Previous_Scores por School Type",
       x = "School Type",
       y = "Media de Notas Previas") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(
  boxplot_exam, barplot_exam,
  boxplot_previous, barplot_previous,
  nrow = 2, ncol = 2
)

```

```{r}
grafico_family_income <- st_clean %>%
  group_by(School_Type, Family_Income) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ggplot(aes(x = School_Type, y = Percentage, fill = Family_Income)) +
  geom_bar(stat = "identity", position = "fill") +
  theme_minimal() +
  labs(title = "Distribución de Family Income por School Type",
       x = "School Type",
       y = "Porcentaje",
       fill = "Family Income") +
  scale_y_continuous(labels = scales::percent) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

grafico_teacher_quality <- st_clean %>%
  group_by(School_Type, Teacher_Quality) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ggplot(aes(x = School_Type, y = Percentage, fill = Teacher_Quality)) +
  geom_bar(stat = "identity", position = "fill") +
  theme_minimal() +
  labs(title = "Distribución de Teacher Quality por School Type",
       x = "School Type",
       y = "Porcentaje",
       fill = "Teacher Quality") +
  scale_y_continuous(labels = scales::percent) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


grid.arrange(grafico_family_income, grafico_teacher_quality, nrow = 1, ncol = 2)

```

## Análisis de horas dormidas

```{r}
st_clean <- st_clean %>%
  mutate(Sleep_Interval = cut(Sleep_Hours, 
                              breaks = c(0, 4, 6, 8, 10, Inf), 
                              labels = c("Muy poco (<4h)", "Poco (4-6h)", "Adecuado (6-8h)", "Bueno (8-10h)", "Excesivo (>10h)"),
                              right = FALSE))

sleep_intervals <- st_clean %>%
  group_by(Sleep_Interval) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100)

grafico_dispersion <- ggplot(st_clean, aes(x = Exam_Score, y = 1, color = Sleep_Interval)) +
  geom_jitter(height = 0.1, width = 0.3, size = 3, alpha = 0.7) +
  scale_color_manual(values = c("Muy poco (<4h)" = "red", 
                                "Poco (4-6h)" = "orange", 
                                "Adecuado (6-8h)" = "green", 
                                "Bueno (8-10h)" = "blue", 
                                "Excesivo (>10h)" = "purple")) +
  theme_minimal() +
  labs(title = "Distribución de Exam Score por Intervalo de Sueño",
       x = "Puntuación del Examen",
       y = "",
       color = "Intervalo de Sueño") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank())

grafico_circular <- ggplot(sleep_intervals, aes(x = "", y = Percentage, fill = Sleep_Interval)) +
  geom_bar(stat = "identity", width = 1, color = "white") +
  coord_polar(theta = "y") +
  scale_fill_manual(values = c("Muy poco (<4h)" = "red", 
                               "Poco (4-6h)" = "orange", 
                               "Adecuado (6-8h)" = "green", 
                               "Bueno (8-10h)" = "blue", 
                               "Excesivo (>10h)" = "purple")) +
  theme_void() +
  labs(title = "Distribución de Intervalos de Sueño (en Porcentaje)",
       fill = "Intervalos de Sueño") +
  geom_text(aes(label = sprintf("%.1f%%", Percentage)), 
            position = position_stack(vjust = 0.5), size = 4)


grid.arrange(grafico_dispersion, grafico_circular, nrow = 1, ncol = 2)


```

Las horas de sueño no tienen gran importancia.

## Conclusión de los análisis de los gráficos

Todos los análisis los mirases por donde los mirasen daban siempre lo mismo, indicando que o bien no tiene ningún tipo de relevancia o el dataset estaba preparado para que solo las 3/4 columnas que mencionamos despues son imporantes.

## Análisis de las 4 correlaciones mayores

```{r}
var1 <- "Hours_Studied"
var2 <- "Previous_Scores"
var3 <- "Attendance"
var4 <- "Tutoring_Sessions"

grafico_var1 <- ggplot(st_clean, aes_string(x = var1, y = "Exam_Score")) +
  geom_point(alpha = 0.7, color = "blue") +
  theme_minimal() +
  labs(title = paste("Relación entre", var1, "y Exam_Score"),
       x = var1,
       y = "Exam Score")

grafico_var2 <- ggplot(st_clean, aes_string(x = var2, y = "Exam_Score")) +
  geom_point(alpha = 0.7, color = "red") +
  theme_minimal() +
  labs(title = paste("Relación entre", var2, "y Exam_Score"),
       x = var2,
       y = "Exam Score")

grafico_var3 <- ggplot(st_clean, aes_string(x = var3, y = "Exam_Score")) +
  geom_point(alpha = 0.7, color = "green") +
  theme_minimal() +
  labs(title = paste("Relación entre", var3, "y Exam_Score"),
       x = var3,
       y = "Exam Score")

grafico_var4 <- ggplot(st_clean, aes(x = as.factor(Tutoring_Sessions), y = Exam_Score, fill = as.factor(Tutoring_Sessions))) +
  geom_boxplot() +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  labs(title = paste("Distribución de Exam_Score por", var4),
       x = "Número de Sesiones de Tutoría",
       y = "Exam Score",
       fill = "Sesiones de Tutoría") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


grid.arrange(grafico_var1, grafico_var2, grafico_var3, grafico_var4, nrow = 2, ncol = 2)


```

### añadimos la recta de regresión

```{r}
var1 <- "Hours_Studied"
var2 <- "Previous_Scores"
var3 <- "Attendance"

grafico_var1 <- ggplot(st_clean, aes_string(x = var1, y = "Exam_Score")) +
  geom_point(alpha = 0.7, color = "blue") +
  geom_smooth(method = "lm", se = FALSE, color = "darkblue") +
  theme_minimal() +
  labs(title = paste("Relación entre", var1, "y Exam_Score"),
       x = var1,
       y = "Exam Score")

grafico_var2 <- ggplot(st_clean, aes_string(x = var2, y = "Exam_Score")) +
  geom_point(alpha = 0.7, color = "red") +
  geom_smooth(method = "lm", se = FALSE, color = "darkred") +
  theme_minimal() +
  labs(title = paste("Relación entre", var2, "y Exam_Score"),
       x = var2,
       y = "Exam Score")

grafico_var3 <- ggplot(st_clean, aes_string(x = var3, y = "Exam_Score")) +
  geom_point(alpha = 0.7, color = "green") +
  geom_smooth(method = "lm", se = FALSE, color = "darkgreen") +
  theme_minimal() +
  labs(title = paste("Relación entre", var3, "y Exam_Score"),
       x = var3,
       y = "Exam Score")

grid.arrange(grafico_var1, grafico_var2, grafico_var3, nrow = 2, ncol = 2)

```

Como podemos comprobar viendo la recta de regresión y el mapa de puntos como nos indicaba el mapa de correlación estos son los 3 valores que mas influyen en la nota del examen.

## Objetivo de los datos

Según vemos en el mapa de correlaciones y analizando el resto de variables y las rectas de regresión correspondientes concluimos que vamos a utilizar una **Regresión lineal múltiple** para predecir el `exam_score`. las variables que incluiremos en esta regresión lineal múltiple serán las siguientes: `attendance`, `hours_studied` y `Previous_score` por orden de peso.

### Creacion de modelo con 3 variables

Elegimos la data para el modelos

```{r}
# Seleccionar las variables relevantes
data_selected <- st_clean %>%
  select(Attendance, Hours_Studied, Previous_Scores, Exam_Score)
```

Entrenamos modelo

```{r}
# Crear el modelo de Regresión Lineal Múltiple
modelo <- lm(Exam_Score ~ Attendance + Hours_Studied + Previous_Scores, data = data_selected)

# Mostrar el resumen del modelo
cat("Resumen del modelo de Regresión Lineal Múltiple:\n")
summary(modelo)

```

los valores residuales:

-   Min: -5.643 de mayor error negativo

-   Max: 31.645 mayor error positivo

-   Mediana: -0.166 La mayoría de los errores están cerca de 0 (Buen signo)

Coeficientes

-   Intercept: 41.99 cuando todas las varibles estudiadas son 0

-   Attendance: 0.198 lo que sube exam_score por cada punto

-   Hours_studied 0.204 lo que sube exam_score por cada punto

-   Previous_score 0.048 lo que sube exam_score por cada punto

valor Pr(\>\|t\|)

Todos los valores son por debajo de 0.001, lo que indica que las variables son **estadisticamente significativas**

Las **métricas del modelo** indican su rendimiento y ajuste. El **R² (0.572)** muestra que el modelo explica el **57.2%** de la variabilidad en **Exam_Score** a partir de las variables **Attendance**, **Hours_Studied** y **Previous_Scores**, mientras que el restante **42.8%** se debe a factores no considerados en el modelo. El **error estándar residual (2.545)** indica que, en promedio, las predicciones del modelo se desvían de los valores reales en aproximadamente **2.55 puntos**. Finalmente, el **F-statistic (2943)** y su p-valor (\<2.2e-16) confirman que el modelo es **estadísticamente significativo**, es decir, al menos una de las variables incluidas tiene un efecto real sobre la predicción de **Exam_Score**.

```{r}
data_selected$predicciones <- predict(modelo1, newdata = data_selected)
# Visualizar valores reales vs predichos
ggplot(data_selected, aes(x = Exam_Score, y = predicciones)) +
  geom_point(color = "blue") + # Puntos que muestran la relación
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Comparación: Valores Reales vs Predichos",
       x = "Exam Score Real",
       y = "Exam Score Predicho") +
  theme_minimal()
```

Este gráfico compara los valores reales de **`Exam_Score`** (eje X) con los valores predichos por el modelo (eje Y). La **línea roja discontinua** representa el ajuste perfecto donde los valores reales y predichos serían iguales. Los **puntos azules** muestran que, en general, el modelo realiza buenas predicciones en valores bajos e intermedios, ya que los puntos están cerca de la línea roja. Sin embargo, a medida que los valores reales aumentan (por encima de 75-80), los puntos presentan **mayor dispersión**, lo que indica que el modelo tiene más errores en valores extremos. Esto concuerda con el **R² del 57.2%**, que sugiere un ajuste moderado del modelo, pero con espacio para mejorar en la predicción de valores atípicos o extremos.

### Creación de modelo con 4 variables

```{r}
data_selected <- st_clean %>%
  select(Attendance, Hours_Studied, Previous_Scores, Exam_Score,Tutoring_Sessions)

# Crear el modelo de Regresión Lineal Múltiple
modelo2 <- lm(Exam_Score ~ Attendance + Hours_Studied + Previous_Scores + Tutoring_Sessions, data = data_selected)

# Mostrar el resumen del modelo
cat("Resumen del modelo de Regresión Lineal Múltiple:\n")
summary(modelo2)

```

```{r}
data_selected$predicciones <- predict(modelo2, newdata = data_selected)

ggplot(data_selected, aes(x = Exam_Score, y = predicciones)) +
  geom_point(color = "blue") + # Puntos que muestran la relación
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Comparación: Valores Reales vs Predichos",
       x = "Exam Score Real",
       y = "Exam Score Predicho") +
  theme_minimal()
```

La diferencia entre la baja correlación de **`Tutoring_Sessions`** con **`Exam_Score`** en el mapa de correlaciones y su mayor peso en el modelo de regresión se debe a que el mapa muestra únicamente **relaciones bivariadas** (directas entre dos variables), mientras que el modelo de regresión lineal múltiple analiza la **relación conjunta** de todas las variables explicativas con la variable dependiente. Aunque **`Tutoring_Sessions`** no tenga una correlación fuerte por sí sola, puede aportar información relevante cuando se consideran simultáneamente las demás variables (**`Attendance`**, **`Hours_Studied`** y **`Previous_Scores`**) y se ajusta por ellas. Esto refleja que su efecto en **`Exam_Score`** puede ser **condicional** y no evidente en la correlación simple, mostrando así una mayor contribución dentro del modelo final.

### Comparación de ambos modelos

```{r}
# Calcular RMSE y R² del primer modelo
pred1 <- predict(modelo1, newdata = data_selected)
rmse1 <- sqrt(mean((data_selected$Exam_Score - pred1)^2))
r2_1 <- summary(modelo1)$r.squared

# Calcular RMSE y R² del segundo modelo
pred2 <- predict(modelo2, newdata = data_selected)
rmse2 <- sqrt(mean((data_selected$Exam_Score - pred2)^2))
r2_2 <- summary(modelo2)$r.squared

# Mostrar resultados
cat("Modelo 1 - RMSE:", rmse1, "R²:", r2_1, "\n")
cat("Modelo 2 - RMSE:", rmse2, "R²:", r2_2, "\n")

```

El **Modelo 2**, que incluye la variable **`Tutoring_Sessions`**, es mejor que el **Modelo 1** porque tiene un **RMSE menor** (2.47 frente a 2.54), lo que indica predicciones más precisas, y un **R² mayor** (59.67% frente a 57.21%), lo que significa que explica mejor la variabilidad de **`Exam_Score`**. Aunque la mejora es moderada, demuestra que **`Tutoring_Sessions`** aporta información útil al modelo.

```{r}
# Definir margen de error aceptable
margen <- 3

# Calcular porcentaje de aciertos para el primer modelo
aciertos1 <- mean(abs(data_selected$Exam_Score - pred1) <= margen) * 100

# Calcular porcentaje de aciertos para el segundo modelo
aciertos2 <- mean(abs(data_selected$Exam_Score - pred2) <= margen) * 100

# Mostrar resultados
cat("Porcentaje de aciertos (±3 puntos) - Modelo 1:", round(aciertos1, 2), "%\n")
cat("Porcentaje de aciertos (±3 puntos) - Modelo 2:", round(aciertos2, 2), "%\n")

```

como hemos predicho en el análisis anterior el modelo 2 es superior al modelo uno, con una precisión del 95.55% frente a la del modelo 1 de un 94.55%

#### Elección del margen de error

Hemos elegido un margen de error de **±3 puntos** porque se ajusta a la **variabilidad de los residuos** observada en el modelo. En concreto, el **residual standard error** (error estándar residual) para ambos modelos está alrededor de **2.5 puntos**, lo cual representa la desviación promedio entre las predicciones y los valores reales. Al establecer un margen de **3 puntos**, cubrimos un rango ligeramente superior a este error estándar, lo que nos permite capturar una gran parte de las predicciones **razonablemente precisas** sin ser ni demasiado estrictos (como un ±2, que dejaría fuera muchas predicciones aceptables) ni demasiado permisivos (como un ±4, que incluiría predicciones con errores considerables). Además, este margen tiene sentido práctico en el contexto de las puntuaciones de un examen, donde pequeñas diferencias de 2 o 3 puntos son aceptables, especialmente si el rango total de calificaciones es amplio (por ejemplo, de 0 a 100). Por lo tanto, el margen de **±3 puntos** equilibra adecuadamente la **precisión estadística** del modelo con la **interpretación práctica** de los resultados.

```{r}
# Generar predicciones para ambos modelos
data_selected$pred_modelo1 <- predict(modelo1, newdata = data_selected)
data_selected$pred_modelo2 <- predict(modelo2, newdata = data_selected)

# Cargar librería para visualización
library(ggplot2)
library(gridExtra) # Para mostrar gráficos en paralelo

# Gráfico del Modelo 1
plot_modelo1 <- ggplot(data_selected, aes(x = Exam_Score, y = pred_modelo1)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Modelo 1: Predichos vs Reales",
       x = "Exam Score Real",
       y = "Exam Score Predicho") +
  theme_minimal()

# Gráfico del Modelo 2
plot_modelo2 <- ggplot(data_selected, aes(x = Exam_Score, y = pred_modelo2)) +
  geom_point(color = "green", alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Modelo 2: Predichos vs Reales",
       x = "Exam Score Real",
       y = "Exam Score Predicho") +
  theme_minimal()

# Mostrar ambos gráficos lado a lado
grid.arrange(plot_modelo1, plot_modelo2, ncol = 2)

```

El **Modelo 2** supera al **Modelo 1** en todas las métricas evaluadas: tiene un menor error (RMSE), un mayor ajuste (R²) y una mayor precisión en las predicciones dentro de un margen de ±3 puntos. Por tanto, la inclusión de la variable **`Tutoring_Sessions`** ha mejorado el rendimiento general del modelo.
