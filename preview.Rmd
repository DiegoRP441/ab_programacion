---
title: "AB programación: Dataset de estudiantes"
output: html_notebook
---

## Explicación del dataset

Diego Romero Puyal.

El dataset ha sido obtenido de la página **Kaggle**: <https://www.kaggle.com/>. De la sección de datasets, específicamente hemos seleccionado este dataset: <https://www.kaggle.com/datasets/lainguyn123/student-performance-factors>. Este conjunto de datos ofrece una visión completa de diversos factores que afectan el rendimiento de los estudiantes en los exámenes. Incluye información sobre hábitos de estudio, asistencia, participación de los padres y otros aspectos que influyen en el éxito académico.

# Parte 1: carga y exploración de datos.

```{r}
library(readr)
library(skimr)
library(dplyr)
library(esquisse)
library(reshape2)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(moments)
library(caret)
library(reticulate)


```

```{python}
import pandas as pd
import scipy.stats as stats
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import CategoricalNB
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
```

Primero importamos el dataset, ademas importamos la librería skimr para la mejor visualización de los datos.

```{r message=FALSE, warning=TRUE, paged.print=TRUE, show_col_types=}
st <- read_csv("estudiantes.csv", show_col_types = FALSE)
head(st,10, show_col_types = FALSE)
```

Tras un primer vistazo podemos observar que tenemos 20 columnas y tenemos tanto valores numéricos como no numéricos. Ademas sospechamos que hay bastantes valores categóricos. Vamos a analizarlo mas a fondo.

Separamos las columnas numéricas de las no numéricas para mejor observación de los datos.

```{r}
numeric_columns <- sapply(st, is.numeric)
```

```{r}
lapply(st[!numeric_columns], unique)

```

Aquí podemos ver que todos las columnas no numéricas son categóricas. esto lo tendremos en cuenta para el análisis y la limpieza mas adelante.

Ahora buscamos los valores nulos dentro de las columnas.

Usamos skim mejor que `summary()` porque da mas información y presentada de forma mas limpia.

```{r}
skim(st[!numeric_columns])
```

Se observa que tenemos valores nulos en 3 columnas: `Teacher_Quality`, `Parental_Educational_Level` y `Distance_From_Home` Mas tarde en la limpieza de datos veremos que hacer con ellos.

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
skim(st[numeric_columns])
```

En los datos numéricos al contrario que pasaba en los no numéricos no tenemos ningún valor nulo.

# Parte 2: Limpieza de datos

Vemos que tenemos valores nulos en 3 columnas:`Parental_Education_Level`, `Teacher_Quality`, `Distance_from_Home`\
Como las 3 columnas que contienen nulos son categóricas vamos a limpiarlas usando la librería `pandas` de python para una mayor facilidad a la hora de trabajar con la moda, debido a que R no tiene una función especifica para calcular la moda.

```{python}


df = pd.read_csv("estudiantes.csv")


```

```{python}

df["Parental_Education_Level"].fillna(df["Parental_Education_Level"].mode()[0], inplace=True)
df["Teacher_Quality"].fillna(df["Teacher_Quality"].mode()[0], inplace=True)
df["Distance_from_Home"].fillna(df["Distance_from_Home"].mode()[0], inplace=True)


```

```{python}

print(df[["Parental_Education_Level", "Teacher_Quality", "Distance_from_Home"]].isnull().sum())
```

Vemos que hemos eliminado correctamente los valores nulos, tras esto devolvemos el csv limpio y empezaremos a analizarlo y trabajar con el en futuros modelos.

Devolvemos el csv limpio y trabajaremos con él.

```{python}
df.to_csv("st_clean.csv", index=False)

```

```{r message=FALSE, warning=TRUE, paged.print=TRUE, show_col_types=}
st_clean <- read_csv("st_clean.csv", show_col_types = FALSE)
head(st_clean,10, show_col_types = FALSE)
```

# Parte 3: Análisis de los datos

Primero comprobamos si existe algún tipo de sesgo en los datos que tenemos en genero y recursos.

```{r}
categorical_vars <- c("Gender", "Family_Income", "School_Type", "Learning_Disabilities")

plots <- list()

for (var in categorical_vars) {
  p <- ggplot(st_clean, aes_string(x = var)) +
    geom_bar(fill = "skyblue") +
    theme_minimal() +
    labs(title = paste("Distribución de", var), x = var, y = "Frecuencia") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  plots[[var]] <- p
}

grid.arrange(grobs = plots, nrow = 2, ncol = 2)

```

Sesgo:

-   **Género**: La distribución es equilibrada, lo que sugiere un bajo riesgo de sesgo.
-   **Ingreso Familiar**: Predominan las clases media y baja, lo que puede influir en los análisis.
-   **Tipo de Escuela**: Mayor representación de escuelas públicas, lo cual podría sesgar los resultados si queremos extrapolarlos hacia grupos donde haya una mayoría de escuela privada.
-   **Discapacidades de Aprendizaje**: Baja representación de estudiantes con discapacidades, lo que podría limitar la representatividad de los análisis en este aspecto.

Podríamos concluir que es un análisis que se podría extrapolar hacia el conjunto mayoritario de la población, es decir, gente de clase media sin `learning_disabilities` y que van a la escuela pública sin tener en cuenta el género.

## Mapa de correlaciones.

```{r}
cor_matrix <- cor(st_clean[, sapply(st_clean, is.numeric)], use = "complete.obs")

melted_cor_matrix <- melt(cor_matrix)

ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +
  geom_text(aes(label = round(value, 2)), color = "black", size = 3) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab",
                       name = "Correlación") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 10, hjust = 1)) +
  coord_fixed() +
  labs(title = "Mapa de Correlación de Variables con Números Visible")

```

En este mapa de calor Podemos observar en las variables numéricas cuales son las que tienen mas peso con la nota del examen. que en este caso podemos ver que son `Attendance` y `Hours_Studied`.

## Distribución de las notas

```{r}
ggplot(st_clean, aes(x = Exam_Score)) +
  geom_histogram(binwidth = 2, fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(title = "Histograma de Distribución de Exam_Score",
       x = "nota del Examen",
       y = "Frecuencia")
```

```{r}
mediana_exam_score <- median(st_clean$Exam_Score, na.rm = TRUE)
media_exam_score <- mean(st_clean$Exam_Score, na.rm = TRUE)

cat("Mediana de Exam_Score:", mediana_exam_score, "\n")
cat("Media de Exam_Score:", media_exam_score, "\n")

```

Podemos ver la distribución de notas de los estudiantes que se concentra entre el 60 y el 70. Ademas podemos decir que es un histograma casi simétrico, la media y la mediana están muy cerca una de otra.

El histograma da una interpretación visual, pero para concretar más vamos a buscar un valor cuantitativo para ver si estamos en lo cierto. Para ello hacemos el análisis de skewness.

```{r}

skewness_exam_score <- skewness(st_clean$Exam_Score, na.rm = TRUE)

cat("Coeficiente de asimetría (skewness):", skewness_exam_score, "\n")

if (abs(skewness_exam_score) < 0.5) {
  cat("La distribución es aproximadamente simétrica.\n")
} else if (skewness_exam_score > 0.5) {
  cat("La distribución está sesgada a la derecha.\n")
} else if (skewness_exam_score < -0.5) {
  cat("La distribución está sesgada a la izquierda.\n")
}

```

El coeficiente de asimetría obtenido es **1.644435**, lo que indica que la distribución está sesgada a la derecha. Esto significa que la cola de la distribución es más larga hacia los valores más altos.

## Análisis por género

Vamos a realizar un análisis centrándonos en el género donde veremos si tiene una relevancia en distintas variables como pueden ser:

```         
Exam_Score,Previous_Scores, Motivation_Level, Tutoring_Sessions, Hours_Studied, Attendance
```

### Notas según género

```{r}
# Crear boxplot para Exam_Score por Gender
boxplot_exam <- ggplot(st_clean, aes(x = Gender, y = Exam_Score, fill = Gender)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Exam_Score por Género",
       x = "Género",
       y = "Notas del Examen") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

# Crear barplot para Exam_Score por Gender
barplot_exam <- st_clean %>%
  group_by(Gender) %>%
  summarise(Media_Exam_Score = mean(Exam_Score, na.rm = TRUE)) %>%
  ggplot(aes(x = Gender, y = Media_Exam_Score, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Media de Exam_Score por Género",
       x = "Género",
       y = "Media de Notas del Examen") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

# Crear boxplot para Previous_Scores por Gender
boxplot_previous <- ggplot(st_clean, aes(x = Gender, y = Previous_Scores, fill = Gender)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Previous_Scores por Género",
       x = "Género",
       y = "Notas Previas") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

# Crear barplot para Previous_Scores por Gender
barplot_previous <- st_clean %>%
  group_by(Gender) %>%
  summarise(Media_Previous_Scores = mean(Previous_Scores, na.rm = TRUE)) %>%
  ggplot(aes(x = Gender, y = Media_Previous_Scores, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Media de Previous_Scores por Género",
       x = "Género",
       y = "Media de Notas Previas") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(
  boxplot_exam, barplot_exam,
  boxplot_previous, barplot_previous,
  nrow = 2, ncol = 2
)

```

```{r}

medias_por_genero <- st_clean %>%
  group_by(Gender) %>%
  summarise(
    Media_Exam_Score = mean(Exam_Score, na.rm = TRUE),
    Media_Previous_Scores = mean(Previous_Scores, na.rm = TRUE)
  )

print(medias_por_genero)
```

Tanto chicas y chicas tienen la misma media.

### Motivación, asistencia, horas de estudio y horas de tutoría según género

```{r}
motivacion_por_genero <- st_clean %>%
  group_by(Gender, Motivation_Level) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ungroup()

grafico_motivacion <- ggplot(motivacion_por_genero, aes(x = Gender, y = Percentage, fill = Motivation_Level)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Distribución porcentual de Motivación por Género",
       x = "Género",
       y = "Porcentaje",
       fill = "Motivación") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

promedio_tutoria_por_genero <- st_clean %>%
  group_by(Gender) %>%
  summarise(Promedio_Tutoring_Sessions = mean(Tutoring_Sessions, na.rm = TRUE))

grafico_tutoria <- ggplot(promedio_tutoria_por_genero, aes(x = Gender, y = Promedio_Tutoring_Sessions, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Promedio de Horas de Tutoría por Género",
       x = "Género",
       y = "Promedio de Horas",
       fill = "Género") +
  geom_text(aes(label = round(Promedio_Tutoring_Sessions, 1)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

promedio_estudio_por_genero <- st_clean %>%
  group_by(Gender) %>%
  summarise(Promedio_Study_Hours = mean(Hours_Studied, na.rm = TRUE))

grafico_estudio <- ggplot(promedio_estudio_por_genero, aes(x = Gender, y = Promedio_Study_Hours, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Promedio de Horas de Estudio por Género",
       x = "Género",
       y = "Promedio de Horas",
       fill = "Género") +
  geom_text(aes(label = round(Promedio_Study_Hours, 1)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

promedio_asistencia_por_genero <- st_clean %>%
  group_by(Gender) %>%
  summarise(Promedio_Attendance = mean(Attendance, na.rm = TRUE))

grafico_asistencia <- ggplot(promedio_asistencia_por_genero, aes(x = Gender, y = Promedio_Attendance, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Promedio de Asistencia por Género",
       x = "Género",
       y = "Promedio de Asistencia",
       fill = "Género") +
  geom_text(aes(label = round(Promedio_Attendance, 1)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(grafico_motivacion, grafico_tutoria, grafico_estudio, grafico_asistencia, nrow = 2, ncol = 2)

```

Se distribuyen de igual manera entre chicos y chicas. El genero no tiene relevancia.

## Análisis según problemas de aprendizaje

```{r}
boxplot_exam <- ggplot(st_clean, aes(x = Learning_Disabilities, y = Exam_Score, fill = Learning_Disabilities)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Exam_Score por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Notas del Examen") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

barplot_exam <- st_clean %>%
  group_by(Learning_Disabilities) %>%
  summarise(Media_Exam_Score = mean(Exam_Score, na.rm = TRUE)) %>%
  ggplot(aes(x = Learning_Disabilities, y = Media_Exam_Score, fill = Learning_Disabilities)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Media de Exam_Score por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Media de Notas del Examen") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

boxplot_previous <- ggplot(st_clean, aes(x = Learning_Disabilities, y = Previous_Scores, fill = Learning_Disabilities)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Previous_Scores por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Notas Previas") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

barplot_previous <- st_clean %>%
  group_by(Learning_Disabilities) %>%
  summarise(Media_Previous_Scores = mean(Previous_Scores, na.rm = TRUE)) %>%
  ggplot(aes(x = Learning_Disabilities, y = Media_Previous_Scores, fill = Learning_Disabilities)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Media de Previous_Scores por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Media de Notas Previas") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(
  boxplot_exam, barplot_exam,
  boxplot_previous, barplot_previous,
  nrow = 2, ncol = 2
)

```

Podemos ver que la existencia de discapacidades para el aprendizaje no tiene influencia en los resultados de los exámenes.

```{r}
motivacion_por_disabilities <- st_clean %>%
  group_by(Learning_Disabilities, Motivation_Level) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ungroup()

grafico_motivacion <- ggplot(motivacion_por_disabilities, aes(x = Learning_Disabilities, y = Percentage, fill = Motivation_Level)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Distribución porcentual de Motivación por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Porcentaje",
       fill = "Motivación") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

promedio_tutoria_por_disabilities <- st_clean %>%
  group_by(Learning_Disabilities) %>%
  summarise(Promedio_Tutoring_Sessions = mean(Tutoring_Sessions, na.rm = TRUE))

grafico_tutoria <- ggplot(promedio_tutoria_por_disabilities, aes(x = Learning_Disabilities, y = Promedio_Tutoring_Sessions, fill = Learning_Disabilities)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Promedio de Horas de Tutoría por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Promedio de Horas",
       fill = "Learning Disabilities") +
  geom_text(aes(label = round(Promedio_Tutoring_Sessions, 1)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

promedio_estudio_por_disabilities <- st_clean %>%
  group_by(Learning_Disabilities) %>%
  summarise(Promedio_Study_Hours = mean(Hours_Studied, na.rm = TRUE))

grafico_estudio <- ggplot(promedio_estudio_por_disabilities, aes(x = Learning_Disabilities, y = Promedio_Study_Hours, fill = Learning_Disabilities)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Promedio de Horas de Estudio por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Promedio de Horas",
       fill = "Learning Disabilities") +
  geom_text(aes(label = round(Promedio_Study_Hours, 1)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

promedio_asistencia_por_disabilities <- st_clean %>%
  group_by(Learning_Disabilities) %>%
  summarise(Promedio_Attendance = mean(Attendance, na.rm = TRUE))

grafico_asistencia <- ggplot(promedio_asistencia_por_disabilities, aes(x = Learning_Disabilities, y = Promedio_Attendance, fill = Learning_Disabilities)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Promedio de Asistencia por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Promedio de Asistencia",
       fill = "Learning Disabilities") +
  geom_text(aes(label = round(Promedio_Attendance, 1)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(grafico_motivacion, grafico_tutoria, grafico_estudio, grafico_asistencia, nrow = 2, ncol = 2)

```

```{r}
grafico_peer_influence <- st_clean %>%
  group_by(Learning_Disabilities, Peer_Influence) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ggplot(aes(x = Learning_Disabilities, y = Percentage, fill = Peer_Influence)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Porcentaje de Peer Influence por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Porcentaje",
       fill = "Peer Influence") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

grafico_parental_involvement <- st_clean %>%
  group_by(Learning_Disabilities, Parental_Involvement) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ggplot(aes(x = Learning_Disabilities, y = Percentage, fill = Parental_Involvement)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Porcentaje de Parental Involvement por Learning Disabilities",
       x = "Learning Disabilities",
       y = "Porcentaje",
       fill = "Parental Involvement") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(grafico_peer_influence, grafico_parental_involvement, nrow = 1, ncol = 2)


```

No hay grandes diferencias entre tener o no tener problemas de aprendizaje

## Análisis según tipo de escuela.

```{r}
boxplot_exam <- ggplot(st_clean, aes(x = School_Type, y = Exam_Score, fill = School_Type)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Exam_Score por School Type",
       x = "School Type",
       y = "Notas del Examen") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

barplot_exam <- st_clean %>%
  group_by(School_Type) %>%
  summarise(Media_Exam_Score = mean(Exam_Score, na.rm = TRUE)) %>%
  ggplot(aes(x = School_Type, y = Media_Exam_Score, fill = School_Type)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Media de Exam_Score por School Type",
       x = "School Type",
       y = "Media de Notas del Examen") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

boxplot_previous <- ggplot(st_clean, aes(x = School_Type, y = Previous_Scores, fill = School_Type)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de Previous_Scores por School Type",
       x = "School Type",
       y = "Notas Previas") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

barplot_previous <- st_clean %>%
  group_by(School_Type) %>%
  summarise(Media_Previous_Scores = mean(Previous_Scores, na.rm = TRUE)) %>%
  ggplot(aes(x = School_Type, y = Media_Previous_Scores, fill = School_Type)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Media de Previous_Scores por School Type",
       x = "School Type",
       y = "Media de Notas Previas") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(
  boxplot_exam, barplot_exam,
  boxplot_previous, barplot_previous,
  nrow = 2, ncol = 2
)

```

```{r}
grafico_family_income <- st_clean %>%
  group_by(School_Type, Family_Income) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ggplot(aes(x = School_Type, y = Percentage, fill = Family_Income)) +
  geom_bar(stat = "identity", position = "fill") +
  theme_minimal() +
  labs(title = "Distribución de Family Income por School Type",
       x = "School Type",
       y = "Porcentaje",
       fill = "Family Income") +
  scale_y_continuous(labels = scales::percent) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

grafico_teacher_quality <- st_clean %>%
  group_by(School_Type, Teacher_Quality) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ggplot(aes(x = School_Type, y = Percentage, fill = Teacher_Quality)) +
  geom_bar(stat = "identity", position = "fill") +
  theme_minimal() +
  labs(title = "Distribución de Teacher Quality por School Type",
       x = "School Type",
       y = "Porcentaje",
       fill = "Teacher Quality") +
  scale_y_continuous(labels = scales::percent) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


grid.arrange(grafico_family_income, grafico_teacher_quality, nrow = 1, ncol = 2)

```

## Análisis de horas dormidas

```{r}
st_clean <- st_clean %>%
  mutate(Sleep_Interval = cut(Sleep_Hours, 
                              breaks = c(0, 4, 6, 8, 10, Inf), 
                              labels = c("Muy poco (<4h)", "Poco (4-6h)", "Adecuado (6-8h)", "Bueno (8-10h)", "Excesivo (>10h)"),
                              right = FALSE))

sleep_intervals <- st_clean %>%
  group_by(Sleep_Interval) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100)

grafico_dispersion <- ggplot(st_clean, aes(x = Exam_Score, y = 1, color = Sleep_Interval)) +
  geom_jitter(height = 0.1, width = 0.3, size = 3, alpha = 0.7) +
  scale_color_manual(values = c("Muy poco (<4h)" = "red", 
                                "Poco (4-6h)" = "orange", 
                                "Adecuado (6-8h)" = "green", 
                                "Bueno (8-10h)" = "blue", 
                                "Excesivo (>10h)" = "purple")) +
  theme_minimal() +
  labs(title = "Distribución de Exam Score por Intervalo de Sueño",
       x = "Puntuación del Examen",
       y = "",
       color = "Intervalo de Sueño") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank())

grafico_circular <- ggplot(sleep_intervals, aes(x = "", y = Percentage, fill = Sleep_Interval)) +
  geom_bar(stat = "identity", width = 1, color = "white") +
  coord_polar(theta = "y") +
  scale_fill_manual(values = c("Muy poco (<4h)" = "red", 
                               "Poco (4-6h)" = "orange", 
                               "Adecuado (6-8h)" = "green", 
                               "Bueno (8-10h)" = "blue", 
                               "Excesivo (>10h)" = "purple")) +
  theme_void() +
  labs(title = "Distribución de Intervalos de Sueño (en Porcentaje)",
       fill = "Intervalos de Sueño") +
  geom_text(aes(label = sprintf("%.1f%%", Percentage)), 
            position = position_stack(vjust = 0.5), size = 4)


grid.arrange(grafico_dispersion, grafico_circular, nrow = 1, ncol = 2)


```

Las horas de sueño no tienen gran importancia.

## Conclusión de los análisis de los gráficos

Todos los análisis los mirases por donde los mirasen daban siempre lo mismo, indicando que o bien no tiene ningún tipo de relevancia o el dataset estaba preparado para que solo las 3/4 columnas que mencionamos después sean importantes.

## Análisis de las 4 correlaciones mayores

```{r}
var1 <- "Hours_Studied"
var2 <- "Previous_Scores"
var3 <- "Attendance"
var4 <- "Tutoring_Sessions"

grafico_var1 <- ggplot(st_clean, aes_string(x = var1, y = "Exam_Score")) +
  geom_point(alpha = 0.7, color = "blue") +
  theme_minimal() +
  labs(title = paste("Relación entre", var1, "y Exam_Score"),
       x = var1,
       y = "Exam Score")

grafico_var2 <- ggplot(st_clean, aes_string(x = var2, y = "Exam_Score")) +
  geom_point(alpha = 0.7, color = "red") +
  theme_minimal() +
  labs(title = paste("Relación entre", var2, "y Exam_Score"),
       x = var2,
       y = "Exam Score")

grafico_var3 <- ggplot(st_clean, aes_string(x = var3, y = "Exam_Score")) +
  geom_point(alpha = 0.7, color = "green") +
  theme_minimal() +
  labs(title = paste("Relación entre", var3, "y Exam_Score"),
       x = var3,
       y = "Exam Score")

grafico_var4 <- ggplot(st_clean, aes(x = as.factor(Tutoring_Sessions), y = Exam_Score, fill = as.factor(Tutoring_Sessions))) +
  geom_boxplot() +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  labs(title = paste("Distribución de Exam_Score por", var4),
       x = "Número de Sesiones de Tutoría",
       y = "Exam Score",
       fill = "Sesiones de Tutoría") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


grid.arrange(grafico_var1, grafico_var2, grafico_var3, grafico_var4, nrow = 2, ncol = 2)


```

### añadimos la recta de regresión

```{r}
var1 <- "Hours_Studied"
var2 <- "Previous_Scores"
var3 <- "Attendance"

grafico_var1 <- ggplot(st_clean, aes_string(x = var1, y = "Exam_Score")) +
  geom_point(alpha = 0.7, color = "blue") +
  geom_smooth(method = "lm", se = FALSE, color = "darkblue") +
  theme_minimal() +
  labs(title = paste("Relación entre", var1, "y Exam_Score"),
       x = var1,
       y = "Exam Score")

grafico_var2 <- ggplot(st_clean, aes_string(x = var2, y = "Exam_Score")) +
  geom_point(alpha = 0.7, color = "red") +
  geom_smooth(method = "lm", se = FALSE, color = "darkred") +
  theme_minimal() +
  labs(title = paste("Relación entre", var2, "y Exam_Score"),
       x = var2,
       y = "Exam Score")

grafico_var3 <- ggplot(st_clean, aes_string(x = var3, y = "Exam_Score")) +
  geom_point(alpha = 0.7, color = "green") +
  geom_smooth(method = "lm", se = FALSE, color = "darkgreen") +
  theme_minimal() +
  labs(title = paste("Relación entre", var3, "y Exam_Score"),
       x = var3,
       y = "Exam Score")

grid.arrange(grafico_var1, grafico_var2, grafico_var3, nrow = 2, ncol = 2)

```

Como podemos comprobar viendo la recta de regresión y el mapa de puntos como nos indicaba el mapa de correlación estos son los 3 valores que mas influyen en la nota del examen.

## Objetivo de los datos

Según vemos en el mapa de correlaciones y analizando el resto de variables y las rectas de regresión correspondientes concluimos que vamos a utilizar una **Regresión lineal múltiple** para predecir el `exam_score`. las variables que incluiremos en esta regresión lineal múltiple serán las siguientes: `attendance`, `hours_studied` y `Previous_score` por orden de peso.

### Creación de modelo con 3 variables

Elegimos los datos para el modelo.

```{r}
data_selected <- st_clean %>%
  select(Attendance, Hours_Studied, Previous_Scores, Exam_Score)
```

Entrenamos modelo.

```{r}

modelo1 <- lm(Exam_Score ~ Attendance + Hours_Studied + Previous_Scores, data = data_selected)

cat("Resumen del modelo de Regresión Lineal Múltiple:\n")
summary(modelo1)

```

los valores residuales:

-   Min: -5.643 de mayor error negativo

-   Max: 31.645 mayor error positivo

-   Mediana: -0.166 La mayoría de los errores están cerca de 0 (Buen signo)

Coeficientes

-   Intercept: 41.99 cuando todas las varibles estudiadas son 0

-   Attendance: 0.198 lo que sube exam_score por cada punto

-   Hours_studied 0.204 lo que sube exam_score por cada punto

-   Previous_score 0.048 lo que sube exam_score por cada punto

valor Pr(\>\|t\|)

Todos los valores son por debajo de 0.001, lo que indica que las variables son **estadisticamente significativas**

Las **métricas del modelo** indican su rendimiento y ajuste. El **R² (0.572)** muestra que el modelo explica el **57.2%** de la variabilidad en **Exam_Score** a partir de las variables **Attendance**, **Hours_Studied** y **Previous_Scores**, mientras que el restante **42.8%** se debe a factores no considerados en el modelo. El **error estándar residual (2.545)** indica que, en promedio, las predicciones del modelo se desvían de los valores reales en aproximadamente **2.55 puntos**. Finalmente, el **F-statistic (2943)** y su p-valor (\<2.2e-16) confirman que el modelo es **estadísticamente significativo**, es decir, al menos una de las variables incluidas tiene un efecto real sobre la predicción de **Exam_Score**.

```{r}
data_selected$predicciones <- predict(modelo1, newdata = data_selected)

ggplot(data_selected, aes(x = Exam_Score, y = predicciones)) +
  geom_point(color = "blue") + # Puntos que muestran la relación
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Comparación: Valores Reales vs Predichos",
       x = "Exam Score Real",
       y = "Exam Score Predicho") +
  theme_minimal()
```

Este gráfico compara los valores reales de **`Exam_Score`** (eje X) con los valores predichos por el modelo (eje Y). La **línea roja discontinua** representa el ajuste perfecto donde los valores reales y predichos serían iguales. Los **puntos azules** muestran que, en general, el modelo realiza buenas predicciones en valores bajos e intermedios, ya que los puntos están cerca de la línea roja. Sin embargo, a medida que los valores reales aumentan (por encima de 75-80), los puntos presentan **mayor dispersión**, lo que indica que el modelo tiene más errores en valores extremos. Esto concuerda con el **R² del 57.2%**, que sugiere un ajuste moderado del modelo, pero con espacio para mejorar en la predicción de valores atípicos o extremos.

### Creación de modelo con 4 variables

```{r}
data_selected <- st_clean %>%
  select(Attendance, Hours_Studied, Previous_Scores, Exam_Score,Tutoring_Sessions)


modelo2 <- lm(Exam_Score ~ Attendance + Hours_Studied + Previous_Scores + Tutoring_Sessions, data = data_selected)

cat("Resumen del modelo de Regresión Lineal Múltiple:\n")
summary(modelo2)

```

```{r}
data_selected$predicciones <- predict(modelo2, newdata = data_selected)

ggplot(data_selected, aes(x = Exam_Score, y = predicciones)) +
  geom_point(color = "blue") + # Puntos que muestran la relación
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Comparación: Valores Reales vs Predichos",
       x = "Exam Score Real",
       y = "Exam Score Predicho") +
  theme_minimal()
```

La diferencia entre la baja correlación de **`Tutoring_Sessions`** con **`Exam_Score`** en el mapa de correlaciones y su mayor peso en el modelo de regresión se debe a que el mapa muestra únicamente **relaciones bivariadas** (directas entre dos variables), mientras que el modelo de regresión lineal múltiple analiza la **relación conjunta** de todas las variables explicativas con la variable dependiente. Aunque **`Tutoring_Sessions`** no tenga una correlación fuerte por sí sola, puede aportar información relevante cuando se consideran simultáneamente las demás variables (**`Attendance`**, **`Hours_Studied`** y **`Previous_Scores`**) y se ajusta por ellas. Esto refleja que su efecto en **`Exam_Score`** puede ser **condicional** y no evidente en la correlación simple, mostrando así una mayor contribución dentro del modelo final.

### Comparación de ambos modelos

```{r}
pred1 <- predict(modelo1, newdata = data_selected)
rmse1 <- sqrt(mean((data_selected$Exam_Score - pred1)^2))
r2_1 <- summary(modelo1)$r.squared

pred2 <- predict(modelo2, newdata = data_selected)
rmse2 <- sqrt(mean((data_selected$Exam_Score - pred2)^2))
r2_2 <- summary(modelo2)$r.squared


cat("Modelo 1 - RMSE:", rmse1, "R²:", r2_1, "\n")
cat("Modelo 2 - RMSE:", rmse2, "R²:", r2_2, "\n")

```

El **Modelo 2**, que incluye la variable **`Tutoring_Sessions`**, es mejor que el **Modelo 1** porque tiene un **RMSE menor** (2.47 frente a 2.54), lo que indica predicciones más precisas, y un **R² mayor** (59.67% frente a 57.21%), lo que significa que explica mejor la variabilidad de **`Exam_Score`**. Aunque la mejora es moderada, demuestra que **`Tutoring_Sessions`** aporta información útil al modelo.

```{r}

data_selected$pred_modelo1 <- predict(modelo1, newdata = data_selected)
data_selected$pred_modelo2 <- predict(modelo2, newdata = data_selected)


plot_modelo1 <- ggplot(data_selected, aes(x = Exam_Score, y = pred_modelo1)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Modelo 1: Predichos vs Reales",
       x = "Exam Score Real",
       y = "Exam Score Predicho") +
  theme_minimal()

plot_modelo2 <- ggplot(data_selected, aes(x = Exam_Score, y = pred_modelo2)) +
  geom_point(color = "green", alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Modelo 2: Predichos vs Reales",
       x = "Exam Score Real",
       y = "Exam Score Predicho") +
  theme_minimal()

grid.arrange(plot_modelo1, plot_modelo2, ncol = 2)

```

El **Modelo 2** supera al **Modelo 1** en todas las métricas evaluadas: tiene un menor error (RMSE), un mayor ajuste (R²) y una mayor precisión en las predicciones dentro de un margen de ±3 puntos. Por tanto, la inclusión de la variable **`Tutoring_Sessions`** ha mejorado el rendimiento general del modelo.

## Validación cruzada.

Estos modelos están diseñados y entrenados con todos los datos del dataset. Esto no se debe de hacer para ello vamos a entrenar ahora otro modelo con las 4 variables pero vamos a separar en dos: testing data, training data. Usaremos el sistema de validación cruzada y dentro de esto usaremos el `10 folds cross validation`, Como el dataset tiene bastante filas de datos es el mas adecuado si hubiese sido mas pequeño el dataset hubiéramos escogido el `leave-one-out`.

Primero elegimos las columnas que nos interesan, tanto la variable dependiente como las variables predictoras.

```{r}
data <- st_clean %>%
  select(Attendance, Hours_Studied, Previous_Scores, Exam_Score,Tutoring_Sessions)

```

Con el paquete caret configuramos el 10-fold cross validation.

```{r}
control <- trainControl(method = "cv", number = 10) 

```

Entrenamos al modelo con validación cruzada.

```{r}

modelo_cv <- train(
  Exam_Score ~ Attendance + Hours_Studied + Previous_Scores + Tutoring_Sessions,
  data = data,
  method = "lm",            
  trControl = control      
)
print(modelo_cv)
```

```{r}
cat("RMSE promedio:", modelo_cv$results$RMSE, "\n")
cat("R² promedio:", modelo_cv$results$Rsquared, "\n")

```

```{r}
predicciones <- predict(modelo_cv, newdata = data)

data$predicciones <- predict(modelo_cv, newdata = data)

ggplot(data, aes(x = Exam_Score, y = predicciones)) +
  geom_point(color = "blue") +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Valores Reales vs Predichos con 10-fold Cross Validation",
       x = "Valores Reales",
       y = "Valores Predichos") +
  theme_minimal()

```

### Comparamos los modelos con y sin validación cruzada

Modelo 2 no tiene la validación cruzada y modelo_cv si tiene validación cruzada con el modelo de 10-fold cross validation.

```{r}
cat("Modelo 2 - RMSE:", rmse2, "R²:", r2_2, "\n")
cat("RMSE promedio:", modelo_cv$results$RMSE, "R² promedio:", modelo_cv$results$Rsquared)
```

```{r}
cat("Modelo 2 - RMSE:", rmse2, "R²:", r2_2, "\n")
cat("RMSE promedio:", modelo_cv$results$RMSE, "R² promedio:", modelo_cv$results$Rsquared)
```

Vemos que mejora pero nada relevante un 0,01321.

## Naive Bayes

cosas para hacer limpiar el dataset para que entre en un naive bayes, y hacerlo.

-   cambiar todas las notas por "no pass", "pass" "merit" "distinction"

-   mirar si alguna categorica es importante a parte de las otras.

```{python}
data = pd.read_csv("st_clean.csv")
```

```{python}
# Crear una nueva columna con las categorías basadas en Exam_Score
data['Exam_Grade'] = pd.cut(
    data['Exam_Score'],
    bins=[0, 49, 59, 79, 100],
    labels=["suspenso", "pass", "merit", "distinction"],
    include_lowest=True
)

# Verificar los cambios
print(data)
```

```{python}
distribucion = data["Exam_Grade"].value_counts()
print(distribucion)
```

Vamos a realizar el ANOVA de las variables categóricas en relación con`exam_score`. Si el p-valor es inferior a 0,05 la relación es significativa, si es superior la relación no es significativa

```{python}
import pandas as pd
import scipy.stats as stats
# Especificar las 13 columnas categóricas manualmente
categorical_columns = [
    'Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities', 
    'Motivation_Level', 'Internet_Access', 'Parental_Education_Level', 
    'School_Type', 'Peer_Influence', 'Learning_Disabilities', 
    'Teacher_Quality', 'Family_Income', 'Gender', 'Distance_from_Home'
]

# Calcular ANOVA entre las variables categóricas y Exam_Score
anova_results = {}

for col in categorical_columns:
    try:
        # Agrupar las puntuaciones de Exam_Score por cada categoría
        unique_values = data[col].unique()
        groups = [data[data[col] == val]['Exam_Score'].dropna() for val in unique_values]
        
        # Calcular ANOVA
        f_stat, p_value = stats.f_oneway(*groups)
        anova_results[col] = {'F-statistic': f_stat, 'P-value': p_value}
    except Exception as e:
        anova_results[col] = {'Error': str(e)}

# Crear un DataFrame para mostrar los resultados
anova_results_df = pd.DataFrame(anova_results).T

# Mostrar los resultados de ANOVA
print(anova_results_df)

```

Tras los resultados del examen de ANOVA concluimos que podemos quedarnos con 10 de 13

-   **Parental_Involvement**

-   **Access_to_Resources**

-   **Extracurricular_Activities**

-   **Motivation_Level**

-   **Internet_Access**

-   **Parental_Education_Level**

-   **Learning_Disabilities**

-   **Teacher_Quality**

-   **Family_Income**

-   **Distance_from_Home**

-   **Peer_Influence**

y eliminaremos del dataset

-   **School_Type**

-   **Gender**

```{python}
drop = ["School_Type", "Gender","Exam_Score" ]
data = data.drop(columns = drop)
```

```{python}
data.head()
```

Comprobamos si hay algun valor nulo antes de crear el modelo para evitar errores

```{python}
print(data.isnull().sum())
```

Vemos que hay un nulo en exam_grade, vamos a rellenar con la moda para evitar errores

```{python}
data["Exam_Grade"].fillna(data["Exam_Grade"].mode()[0], inplace=True)
```

```{python}
print(data.isnull().sum())
```

Una vez tenemos el dataset preparado vamos a preparar el modelo. `X` Serán las variables predictoras e `y` será la variable a la que predecir.

```{python}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.naive_bayes import GaussianNB
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, accuracy_score

# Separar las características (X) y la variable objetivo (y)
X = data[['Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities',
          'Motivation_Level', 'Internet_Access', 'Parental_Education_Level',
          'Learning_Disabilities', 'Teacher_Quality', 'Family_Income',
          'Distance_from_Home', 'Peer_Influence', 'Attendance',
          'Hours_Studied', 'Previous_Scores', 'Tutoring_Sessions']]
y = data['Exam_Grade']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Identificar las columnas categóricas y numéricas
categorical_features = ['Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities',
                        'Motivation_Level', 'Internet_Access', 'Parental_Education_Level',
                        'Learning_Disabilities', 'Teacher_Quality', 'Family_Income',
                        'Distance_from_Home', 'Peer_Influence']
numerical_features = ['Attendance', 'Hours_Studied', 'Previous_Scores', 'Tutoring_Sessions']

# Crear los transformadores para preprocesar los datos
categorical_transformer = OneHotEncoder(drop='first', handle_unknown='ignore')
numerical_transformer = StandardScaler()

# Crear un ColumnTransformer para aplicar los preprocesamientos
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', categorical_transformer, categorical_features),
        ('num', numerical_transformer, numerical_features)
    ])

# Crear un pipeline que incluye el preprocesamiento y el modelo
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', GaussianNB())
])

# Entrenar el modelo
pipeline.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
y_pred = pipeline.predict(X_test)

# Evaluar el modelo
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

```

```{python}
print(y.value_counts())


```

```{python}
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.over_sampling import SMOTE
import pandas as pd

# Supongamos que 'categorical_features' y 'numerical_features' ya están definidas
categorical_features = ['Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities',
                        'Motivation_Level', 'Internet_Access', 'Parental_Education_Level',
                        'Learning_Disabilities', 'Teacher_Quality', 'Family_Income',
                        'Distance_from_Home', 'Peer_Influence']
numerical_features = ['Attendance', 'Hours_Studied', 'Previous_Scores', 'Tutoring_Sessions']

# Aplicar OneHotEncoder a las columnas categóricas
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)
    ],
    remainder='passthrough'  # Mantener las columnas numéricas como están
)

# Transformar los datos
X_transformed = preprocessor.fit_transform(X)

# Aplicar SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_transformed, y)

# Verificar las nuevas distribuciones
print(pd.Series(y_resampled).value_counts())



```

```{python}
# Crear un DataFrame a partir de los datos sobremuestreados
X_resampled_df = pd.DataFrame(X_resampled, columns=preprocessor.get_feature_names_out())
y_resampled_df = pd.DataFrame(y_resampled, columns=['Exam_Grade'])

# Combinar las características y las etiquetas en un solo DataFrame
resampled_data = pd.concat([X_resampled_df, y_resampled_df], axis=1)

# Guardar el DataFrame en un archivo CSV
resampled_data.to_csv('resampled_dataset.csv', index=False)
print("Dataset sobremuestreado guardado como 'resampled_dataset.csv'")

```

```{python}
data2 = pd.read_csv("resampled_dataset.csv")
```

```{python}

# Separar características (X) y la variable objetivo (y)
X = data2.drop(columns=['Exam_Grade'])  # Todas las columnas excepto 'Exam_Grade'
y = data2['Exam_Grade']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Crear el modelo GaussianNB
model = GaussianNB()

# Entrenar el modelo
model.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
y_pred = model.predict(X_test)

# Evaluar el modelo
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))


```
